# LG U+ ìš”ê¸ˆì œ ì§ˆì˜ ì±—ë´‡ V1
import pandas as pd
import chromadb
from openai import OpenAI
import os
import json

# --- (ì´ì „ê³¼ ë™ì¼í•œ ì„¤ì • ë¶€ë¶„) ---
try:
    client = OpenAI(api_key="API_KEY")
    print("âœ… OpenAI API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except KeyError:
    print("âŒ 'OPENAI_API_KEY' í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit()

db_path = "chroma_db"
persistent_client = chromadb.PersistentClient(path=db_path)
collection_name = "lgu_plans_upgraded"
try:
    collection = persistent_client.get_collection(name=collection_name)
    print(f"âœ… ChromaDB í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆê³ , '{collection_name}' ì»¬ë ‰ì…˜ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except ValueError:
    print(f"âŒ '{collection_name}' ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. DB ì…‹ì—…ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit()

# ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ (Pandas ì¡°ê±´ ê²€ìƒ‰ìš©)
try:
    full_df = pd.read_csv('lgu_plans_refined.csv')
    print("âœ… ì¡°ê±´ ê²€ìƒ‰ì„ ìœ„í•´ ì „ì²´ ìš”ê¸ˆì œ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except FileNotFoundError:
    print("âŒ 'lgu_plans_refined.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

EMBEDDING_MODEL = "text-embedding-3-small"
LLM_MODEL = "gpt-4o"


# --- (generate_final_answer, setup_database í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼) ---
def generate_final_answer(query, retrieved_info):
    # ... ì´ì „ ì½”ë“œì™€ ë™ì¼ ...
    print("ğŸ¤– LLMì´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    system_prompt = """
    ë‹¹ì‹ ì€ LG U+ ëª¨ë°”ì¼ ìš”ê¸ˆì œ ì „ë¬¸ ìƒë‹´ì›ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ 'ì°¸ê³  ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ 'ì§ˆë¬¸'ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    - í•­ìƒ 'ì°¸ê³  ì •ë³´'ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
    - ê°€ê²© ì •ë³´ëŠ” 'ì›” x,xxxì›' í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”.
    - ê° ìš”ê¸ˆì œì˜ í•µì‹¬ íŠ¹ì§•ì„ ì˜ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    - ë§Œì•½ ì°¸ê³  ì •ë³´ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë‹¤ë©´, "ì£„ì†¡í•˜ì§€ë§Œ ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    """
    user_prompt = f"[ì°¸ê³  ì •ë³´]\n{json.dumps(retrieved_info, indent=2, ensure_ascii=False)}\n\n[ì§ˆë¬¸]\n{query}"
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            temperature=0.2
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# --- ê²€ìƒ‰ ë„êµ¬ë“¤ ì •ì˜ ---

def search_plans_from_db(query, top_k=5):
    """[ë„êµ¬ 1: ì˜ë¯¸ ê²€ìƒ‰] ChromaDBì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ìš”ê¸ˆì œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    print(f"\nğŸ” (ì˜ë¯¸ ê²€ìƒ‰) '{query}' ê´€ë ¨ ì •ë³´ë¥¼ ChromaDBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    query_embedding = client.embeddings.create(input=[query], model=EMBEDDING_MODEL).data[0].embedding
    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)
    print(f"âœ… {len(results['metadatas'][0])}ê°œì˜ ê´€ë ¨ ìš”ê¸ˆì œ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return results['metadatas'][0]


def search_plans_with_pandas(operation, column, top_k=3):
    """[ë„êµ¬ 2: ì¡°ê±´ ê²€ìƒ‰] Pandasë¡œ ë°ì´í„°ë¥¼ ì •ë ¬/í•„í„°ë§í•©ë‹ˆë‹¤."""
    print(f"\nâš™ï¸ (ì¡°ê±´ ê²€ìƒ‰) Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ '{column}' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ '{operation}' ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

    if operation == 'max':
        result_df = full_df.sort_values(by=column, ascending=False).head(top_k)
    elif operation == 'min':
        result_df = full_df.sort_values(by=column, ascending=True).head(top_k)
    else:
        return []

    return json.loads(result_df.to_json(orient='records'))


# --- ë§¤ë‹ˆì € í•¨ìˆ˜ ì •ì˜ ---

def chatbot_manager(query):
    """ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ë§¤ë‹ˆì € ì—­í• ì„ í•©ë‹ˆë‹¤."""
    print(f"\nğŸ§  ë§¤ë‹ˆì €ê°€ '{query}' ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤...")

    # LLMì„ ì´ìš©í•œ ì˜ë„ íŒŒì•… í”„ë¡¬í”„íŠ¸
    intent_prompt = f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ê²€ìƒ‰ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ”ì§€ ê²°ì •í•˜ê³ , í•„ìš”í•œ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì¤˜.
    ê²€ìƒ‰ ìœ í˜•ì€ 'semantic' (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰) ë˜ëŠ” 'structured' (ì¡°ê±´ ê¸°ë°˜ ê²€ìƒ‰) ì¤‘ í•˜ë‚˜ì•¼.

    - "ì œì¼ ë¹„ì‹¼", "ê°€ì¥ ì €ë ´í•œ", "ìµœê³ ê°€" ë“±ì˜ ì§ˆë¬¸ì€ 'structured' ê²€ìƒ‰ì´ì•¼. 'operation'ì€ 'max' ë˜ëŠ” 'min'ìœ¼ë¡œ, 'column'ì€ 'monthly_price'ë¡œ ì„¤ì •í•´ì¤˜.
    - "ë°ì´í„° ì œì¼ ë§ì€" ë“±ì˜ ì§ˆë¬¸ë„ 'structured' ê²€ìƒ‰ì´ì•¼. 'operation'ì€ 'max'ë¡œ, 'column'ì€ 'data_gb'ë¡œ ì„¤ì •í•´ì¤˜.
    - ê·¸ ì™¸ "ì•¼ë¬´ì§„", "ì“¸ë§Œí•œ", "ì²­ì†Œë…„ìš©" ë“± ì¶”ìƒì ì¸ ì¶”ì²œ ìš”ì²­ì€ ëª¨ë‘ 'semantic' ê²€ìƒ‰ì´ì•¼.

    ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

    JSON ì¶œë ¥:
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": intent_prompt}],
        response_format={"type": "json_object"},
        temperature=0.0
    )

    try:
        intent_result = json.loads(response.choices[0].message.content)
        search_type = intent_result.get('search_type')
        print(f"âœ… ì˜ë„ íŒŒì•… ì™„ë£Œ: {search_type}")

        retrieved_plans = []
        if search_type == 'structured':
            # ì¡°ê±´ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
            operation = intent_result.get('operation')
            column = intent_result.get('column')
            retrieved_plans = search_plans_with_pandas(operation, column)
        else:  # 'semantic' ë˜ëŠ” ë¯¸ë¶„ë¥˜
            # ì˜ë¯¸ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
            retrieved_plans = search_plans_from_db(query)

        if not retrieved_plans:
            print("ê´€ë ¨ ìš”ê¸ˆì œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        # ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
        final_answer = generate_final_answer(query, retrieved_plans)

        print("\n---------- ì±—ë´‡ ìµœì¢… ë‹µë³€ ----------")
        print(final_answer)
        print("------------------------------------")

    except (json.JSONDecodeError, KeyError) as e:
        print(f"ğŸš¨ ì˜ë„ íŒŒì•… ê²°ê³¼(JSON)ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("ê¸°ë³¸ ì˜ë¯¸ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì˜ë¯¸ ê²€ìƒ‰ ì‹¤í–‰
        retrieved_plans = search_plans_from_db(query)
        final_answer = generate_final_answer(query, retrieved_plans)
        print("\n---------- ì±—ë´‡ ìµœì¢… ë‹µë³€ ----------")
        print(final_answer)
        print("------------------------------------")


# --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---
if __name__ == "__main__":
    print("\n==================================================")
    print("ğŸ¤– LG U+ ìš”ê¸ˆì œ ìƒë‹´ ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤. (v2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)")
    print("==================================================")

    while True:
        user_query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ì‹œë ¤ë©´ 'ì¢…ë£Œ' ì…ë ¥): ")
        if user_query.strip().lower() == 'ì¢…ë£Œ':
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.")
            break
        if not user_query.strip():
            print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        # ë§¤ë‹ˆì € í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì±—ë´‡ ì‹¤í–‰
        chatbot_manager(user_query)