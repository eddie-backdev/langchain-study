# lgu_plan_chatbot_langchain/02_chatbot_langchain.py

import pandas as pd
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain.agents import tool, AgentExecutor, create_react_agent
from langchain import hub
import os
import json
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- 1. ê¸°ë³¸ ì„¤ì • ---
CHROMA_DB_PATH = "chroma_db_langchain"
REFINED_CSV_PATH = 'lgu_plans_refined.csv'
EMBEDDING_MODEL = "text-embedding-3-small"
LLM_MODEL = "gpt-4o"

# --- API í‚¤ ë° DB/ë°ì´í„° íŒŒì¼ í™•ì¸ ---
try:
    api_key = os.environ["OPENAI_API_KEY"]
    print("âœ… OpenAI API í‚¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except KeyError:
    print("âŒ 'OPENAI_API_KEY' í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    exit()

if not os.path.exists(CHROMA_DB_PATH):
    print(f"âŒ ChromaDB ë””ë ‰í† ë¦¬('{CHROMA_DB_PATH}')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ë¨¼ì € 01_setup_database.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    exit()

if not os.path.exists(REFINED_CSV_PATH):
    print(f"âŒ ì›ë³¸ ë°ì´í„° íŒŒì¼('{REFINED_CSV_PATH}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# --- 2. LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ---
print("ğŸ”— LangChain ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
# LLM, ì„ë² ë”©, ë²¡í„° ì €ì¥ì†Œ, ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
llm = ChatOpenAI(model=LLM_MODEL, temperature=0, api_key=api_key)
embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, api_key=api_key)
vector_store = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)
retriever = vector_store.as_retriever(search_kwargs={'k': 5})

# ì „ì²´ ë°ì´í„° ë¡œë“œ (ì¡°ê±´ ê²€ìƒ‰ìš©)
full_df = pd.read_csv(REFINED_CSV_PATH)
print("âœ… ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ.")


# --- 3. ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë„êµ¬(Tool) ì •ì˜ ---

@tool
def semantic_search(query: str):
    """(ì˜ë¯¸ ê²€ìƒ‰) ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ìš”ê¸ˆì œ ì •ë³´ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ì˜ˆ: 'ì²­ì†Œë…„ì—ê²Œ ì“¸ë§Œí•œ ìš”ê¸ˆì œ', 'ë°ì´í„° ë§ì´ ì“°ëŠ” ì‚¬ëŒì—ê²Œ ì¢‹ì€ ìš”ê¸ˆì œ', 'ê°€ì„±ë¹„ ì¢‹ì€ ìš”ê¸ˆì œ' ë“± ì¶”ìƒì ì¸ ì§ˆë¬¸ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"\n>> ë„êµ¬ ì‹¤í–‰: semantic_search(query='{query}')")

    # RAG Chain ì •ì˜ (LCEL - LangChain Expression Language)
    prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ LG U+ ìš”ê¸ˆì œ ì „ë¬¸ ìƒë‹´ì›ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ [ì°¸ê³  ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [ì§ˆë¬¸]ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        - í•­ìƒ [ì°¸ê³  ì •ë³´]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
        - ê°€ê²© ì •ë³´ëŠ” 'ì›” x,xxxì›' í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ì£¼ì„¸ìš”.
        - ê° ìš”ê¸ˆì œì˜ í•µì‹¬ íŠ¹ì§•ì„ ì˜ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        - ë§Œì•½ ì°¸ê³  ì •ë³´ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë‹¤ë©´, "ì£„ì†¡í•˜ì§€ë§Œ ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

        [ì°¸ê³  ì •ë³´]
        {context}

        [ì§ˆë¬¸]
        {question}
        """
    )

    def format_docs(docs):
        # ê²€ìƒ‰ëœ Document ê°ì²´ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
        return "\n\n".join(doc.page_content for doc in docs)

    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    # RAG ì²´ì¸ ì‹¤í–‰
    result = rag_chain.invoke(query)
    return result


@tool
def structured_search(operation: str, column: str):
    """(ì¡°ê±´ ê²€ìƒ‰) íŠ¹ì • ì¡°ê±´(ê°€ì¥ ë¹„ì‹¼/ì €ë ´í•œ, ê°€ì¥ ë§ì€/ì ì€)ì— ë§ëŠ” ìš”ê¸ˆì œë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    'operation' ì¸ìì—ëŠ” 'max'(ìµœëŒ€) ë˜ëŠ” 'min'(ìµœì†Œ)ì„, 'column' ì¸ìì—ëŠ” 'monthly_price'(ê°€ê²©) ë˜ëŠ” 'data_gb'(ë°ì´í„°)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ì˜ˆ: 'ê°€ì¥ ë¹„ì‹¼ ìš”ê¸ˆì œ', 'ë°ì´í„°ê°€ ê°€ì¥ ë§ì€ ìš”ê¸ˆì œ'
    """
    print(f"\n>> ë„êµ¬ ì‹¤í–‰: structured_search(operation='{operation}', column='{column}')")

    if column not in ['monthly_price', 'data_gb'] or operation not in ['max', 'min']:
        return "ì˜ëª»ëœ ì¸ìì…ë‹ˆë‹¤. columnì€ 'monthly_price' ë˜ëŠ” 'data_gb', operationì€ 'max' ë˜ëŠ” 'min' ì´ì–´ì•¼ í•©ë‹ˆë‹¤."

    ascending = True if operation == 'min' else False
    result_df = full_df.sort_values(by=column, ascending=ascending).head(3)

    # ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ LLMì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ë§Œë“¦
    result_json = result_df.to_json(orient='records', force_ascii=False)

    # ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•´ LLM í˜¸ì¶œ
    prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ LG U+ ìš”ê¸ˆì œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ [ìš”ê¸ˆì œ ë°ì´í„°]ë¥¼ ë³´ê³ , ì‚¬ìš©ìì˜ [ì§ˆë¬¸] ì˜ë„ì— ë§ê²Œ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

        [ìš”ê¸ˆì œ ë°ì´í„°]
        {context}

        [ì§ˆë¬¸]
        {question}
        """
    )
    chain = prompt | llm | StrOutputParser()
    # ì›ë˜ ì§ˆë¬¸ì„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
    original_query = f"{column}ì„ ê¸°ì¤€ìœ¼ë¡œ {operation} ê°’ì„ ê°€ì§€ëŠ” ìš”ê¸ˆì œ ì°¾ì•„ì¤˜"
    result = chain.invoke({"context": result_json, "question": original_query})
    return result


# --- 4. ì—ì´ì „íŠ¸(Agent) ìƒì„± ë° ì‹¤í–‰ ---

tools = [semantic_search, structured_search]

# ReAct í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (Agentê°€ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ìƒê°í•˜ê³  í–‰ë™í• ì§€ ì •ì˜í•œ í…œí”Œë¦¿)
# https://smith.langchain.com/hub/hwchase17/react
prompt = hub.pull("hwchase17/react")

# ì—ì´ì „íŠ¸ ìƒì„±
agent = create_react_agent(llm, tools, prompt)

# ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°(Executor) ìƒì„±
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)


# --- 5. ë©”ì¸ ì‹¤í–‰ ë£¨í”„ ---
if __name__ == "__main__":
    print("\n==================================================")
    print("ğŸ¤– LG U+ ìš”ê¸ˆì œ ìƒë‹´ ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤. (v3. LangChain Agent)")
    print("==================================================")

    while True:
        user_query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ì‹œë ¤ë©´ 'ì¢…ë£Œ' ì…ë ¥): ")
        if user_query.strip().lower() == 'ì¢…ë£Œ':
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.")
            break
        if not user_query.strip():
            print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ì‹¤í–‰
        response = agent_executor.invoke({"input": user_query})

        print("\n---------- ì±—ë´‡ ìµœì¢… ë‹µë³€ ----------")
        print(response['output'])
        print("------------------------------------")
